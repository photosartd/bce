{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Install Dependencies"
   ],
   "metadata": {
    "id": "PzzGxKTS-Ri2",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For now only CPU runtime, some problems with GPU"
   ],
   "metadata": {
    "id": "vYP64GGPH_50",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/photosartd/bce.git\n",
    "%cd bce\n",
    "!git fetch origin dev\n",
    "!git checkout dev\n",
    "#%env PYTHONPATH=/env/python:/content/bce\n",
    "!pip install -q -e ."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CURx97bz8-rb",
    "outputId": "a3c54f48-ef3d-46f8-f785-f1a598ec9093",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fatal: destination path 'bce' already exists and is not an empty directory.\n",
      "/content/bce\n",
      "From https://github.com/photosartd/bce\n",
      " * branch            dev        -> FETCH_HEAD\n",
      "Already on 'dev'\n",
      "Your branch is up to date with 'origin/dev'.\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.0 which is incompatible.\n",
      "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.0 which is incompatible.\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YE5U9iZ43kMN",
    "outputId": "39a81f9c-a535-40d9-848d-bf33c5a40e63",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Errno 2] No such file or directory: 'bce'\n",
      "/content/bce\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch-bce 0.1.0 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\u001B[0m\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch-bce 0.1.0 requires numpy>=1.23.0, but you have numpy 1.22.4 which is incompatible.\u001B[0m\n",
      "\u001B[K     |████████████████████████████████| 48 kB 2.7 MB/s \n",
      "\u001B[?25h  Building wheel for torch-geometric-temporal (setup.py) ... \u001B[?25l\u001B[?25hdone\n"
     ]
    }
   ],
   "source": [
    "%cd bce\n",
    "\n",
    "import torch\n",
    "\n",
    "def format_pytorch_version(version):\n",
    "  return version.split('+')[0]\n",
    "\n",
    "TORCH_version = torch.__version__\n",
    "TORCH = format_pytorch_version(TORCH_version)\n",
    "\n",
    "def format_cuda_version(version):\n",
    "  return 'cu' + version.replace('.', '')\n",
    "\n",
    "CUDA_version = torch.version.cuda\n",
    "CUDA = format_cuda_version(CUDA_version)\n",
    "\n",
    "!pip install torch-scatter -q -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-sparse -q -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-cluster -q -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-spline-conv -q -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
    "!pip install torch-geometric -q\n",
    "\n",
    "!pip install wandb==0.13.3 -q\n",
    "\n",
    "!pip install torch-geometric-temporal -q"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Restart runtime**"
   ],
   "metadata": {
    "id": "VRl-WqM29jsO",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Process"
   ],
   "metadata": {
    "id": "Z-QjlORy-tdQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0HrQkhd46pU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Iterable\n",
    "from functools import cached_property\n",
    "from tempfile import TemporaryDirectory\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader, WikiMathsDatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "from torch_bce.models import GraphSAGE, MLPRegressor\n",
    "from torch_bce.losses import GraphSageLoss\n",
    "from torch_bce.utils.datasets import TensorSupervisedDataset\n",
    "from torch_bce.trainers.gs_alignment_trainer import GSAlignmentTrainer"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "KWARGS = {\n",
    "    \"lambda_\": 2,\n",
    "    \"alignment\": \"multi_step\",\n",
    "    \"backward_transformation\": \"linear\",\n",
    "    \"level\": logging.INFO,\n",
    "    \"num_epochs\": 100,\n",
    "    \"setup_wandb\": True\n",
    "}\n",
    "DEVICE = \"cpu\" #some problems with GPU for now"
   ],
   "metadata": {
    "id": "EWFKr_BdNvgi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load temporal graph dataset:"
   ],
   "metadata": {
    "id": "R-dYK_3YC9sw",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loader = WikiMathsDatasetLoader()  # ChickenpoxDatasetLoader()\n",
    "dataset = loader.get_dataset()\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.2)"
   ],
   "metadata": {
    "id": "Cb5IetZYN-mT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up **Intended Model**"
   ],
   "metadata": {
    "id": "Z-l7qSo2DDcV",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_node_features = train_dataset[0].num_node_features\n",
    "\"\"\"Intended model\"\"\"\n",
    "hid_channels = 128\n",
    "out_channels = 32\n",
    "intended_model = GraphSAGE(\n",
    "    loss=GraphSageLoss(),\n",
    "    in_channels=num_node_features,\n",
    "    hid_channels=hid_channels,\n",
    "    out_channels=out_channels,\n",
    "    n_layers=2,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")"
   ],
   "metadata": {
    "id": "1ijJBQIBDK5X",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up **Unintended Model**"
   ],
   "metadata": {
    "id": "8ViAmUToDR0V",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"Unintended model\"\"\"\n",
    "unintended_model = MLPRegressor(loss=nn.MSELoss(), input_size=out_channels, output_size=1, div=3)\n",
    "unintended_opt = torch.optim.Adam(unintended_model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "id": "5NVS33a8DWnt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up **Trainer**"
   ],
   "metadata": {
    "id": "5oAWDNkVDfpk",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "local_kwargs = deepcopy(KWARGS)\n",
    "local_kwargs[\"setup_wandb\"] = True\n",
    "trainer = GSAlignmentTrainer(\n",
    "    model=intended_model,\n",
    "    **local_kwargs\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "oimytZPwDeh-",
    "outputId": "31de8676-210f-4a07-f797-2272f38aa4f1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mdimaks27\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20221220_194649-1vcxpzrd</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dimaks27/bce/runs/1vcxpzrd\" target=\"_blank\">solar-smoke-173</a></strong> to <a href=\"https://wandb.ai/dimaks27/bce\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train Intended Model for several epochs:"
   ],
   "metadata": {
    "id": "Zfhx4E18DmDI",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "N_EPOCHS = 11"
   ],
   "metadata": {
    "id": "XcP0CjB7DtlX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"Training Intended\"\"\"\n",
    "optimizer = torch.optim.Adam(intended_model.parameters(), lr=3e-4, weight_decay=4e-5)\n",
    "losses = []\n",
    "for epoch in range(1, N_EPOCHS):\n",
    "    loss = 0\n",
    "    time: int = 1\n",
    "    for time, data in enumerate(train_dataset, 1):\n",
    "        model_loss, statistics = trainer.train(\n",
    "            train_data=data,\n",
    "            val_data=test_dataset[0],\n",
    "            walk_length=3,\n",
    "            sizes=(5, 2),\n",
    "            batch_size=256,\n",
    "            shuffle=False,\n",
    "            log_stats=False\n",
    "        )\n",
    "        loss = loss + model_loss\n",
    "    loss = loss / time\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    trainer.log_metrics(epoch, statistics)\n",
    "\"\"\"Get predictions for latest snapshot\"\"\"\n",
    "predictions = []\n",
    "ys = []\n",
    "for data in train_dataset:\n",
    "    curr_predictions, stats = trainer.inference(\n",
    "        data,\n",
    "        walk_length=3,\n",
    "        sizes=(5, 2),\n",
    "        batch_size=256,\n",
    "        shuffle=False,\n",
    "        log_stats=False\n",
    "    )\n",
    "    predictions.append(curr_predictions)\n",
    "    ys.append(data.y)\n",
    "predictions = torch.vstack(predictions)\n",
    "ys = torch.hstack(ys)\n",
    "\n",
    "predictions_test = []\n",
    "ys_test = []\n",
    "for data in test_dataset:\n",
    "    curr_predictions_test, stats_test = trainer.inference(\n",
    "        data,\n",
    "        walk_length=3,\n",
    "        sizes=(5, 2),\n",
    "        batch_size=256,\n",
    "        shuffle=False,\n",
    "        log_stats=False\n",
    "    )\n",
    "    predictions_test.append(curr_predictions_test)\n",
    "    ys_test.append(data.y)\n",
    "predictions_test = torch.vstack(predictions_test)\n",
    "ys_test = torch.hstack(ys_test)"
   ],
   "metadata": {
    "id": "tJTkVSHEN49j",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train Unintended model on embeddings:"
   ],
   "metadata": {
    "id": "ZHCzK1cvD7LR",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "N_EPOCHS = 20"
   ],
   "metadata": {
    "id": "2SJwzxCyEMyU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"Training unintended\"\"\"\n",
    "unintended_dataset = TensorSupervisedDataset(\n",
    "    x=predictions,\n",
    "    y=ys\n",
    ")\n",
    "unintended_dataloader = DataLoader(unintended_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "unintended_dataset_val = TensorSupervisedDataset(\n",
    "    x=predictions_test,\n",
    "    y=ys_test\n",
    ")\n",
    "unintended_dataloader_val = DataLoader(unintended_dataset_val, batch_size=256, shuffle=False)\n",
    "unintended_losses = []\n",
    "for epoch in range(1, N_EPOCHS):\n",
    "    loss, metrics = unintended_model.train_loop(unintended_dataloader, unintended_opt)\n",
    "    preds_val, metrics_val = unintended_model.predict(unintended_dataloader_val)\n",
    "    trainer.log_metrics(\n",
    "        epoch=epoch,\n",
    "        metrics={\n",
    "            \"Unintended: train loss\": metrics[\"mean_train_loss\"],\n",
    "            \"Unintended: val loss\": metrics_val[\"mean_loss\"],\n",
    "            \"Unintended: MSE train\": metrics[\"MeanSquaredError\"],\n",
    "            \"Unintended: MSE val\": metrics_val[\"MeanSquaredError\"],\n",
    "            \"Unintended: MAE train\": metrics[\"MeanAbsoluteError\"],\n",
    "            \"Unintended: MAE val\": metrics_val[\"MeanAbsoluteError\"]\n",
    "        }\n",
    "    )\n",
    "    unintended_losses.append(metrics[\"mean_train_loss\"])"
   ],
   "metadata": {
    "id": "5I14e3igN7DM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Time to create, replace in trainer and train 2-nd Intended Model:"
   ],
   "metadata": {
    "id": "3VKB4mAAEZ67",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"Intended model 2\"\"\"\n",
    "intended_model_new = GraphSAGE(\n",
    "    loss=GraphSageLoss(),\n",
    "    in_channels=num_node_features,\n",
    "    hid_channels=hid_channels // 2,\n",
    "    out_channels=out_channels,\n",
    "    n_layers=3,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "optimizer = torch.optim.Adam(intended_model_new.parameters(), lr=3e-4, weight_decay=4e-5)\n",
    "\"\"\"Replace model\"\"\"\n",
    "trainer.replace_model(\n",
    "    intended_model_new,\n",
    "    train_data=test_dataset[0],\n",
    "    walk_length=3,\n",
    "    sizes=(5, 2),\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    log_stats=False\n",
    ")\n",
    "\"\"\"Train intended again\"\"\"\n",
    "losses = []\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(trainer.alignment_optimizer, step_size=50, gamma=0.1)\n",
    "for epoch in range(1, N_EPOCHS + 70):\n",
    "    loss2 = 0\n",
    "    time: int = 1\n",
    "    for time, data in enumerate(train_dataset, 1):\n",
    "        model_loss, statistics = trainer.train(\n",
    "            train_data=data.to(DEVICE),\n",
    "            val_data=test_dataset[0].to(DEVICE),\n",
    "            walk_length=3,\n",
    "            sizes=(5, 2, 1),\n",
    "            batch_size=256,\n",
    "            shuffle=False,\n",
    "            log_stats=False\n",
    "        )\n",
    "        loss2 = loss2 + model_loss\n",
    "    loss2 = loss2 / time\n",
    "    losses.append(loss2.item())\n",
    "    loss2.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    \"\"\"Get preds on step\"\"\"\n",
    "    predictions_test = []\n",
    "    ys_test = []\n",
    "    for data in test_dataset:\n",
    "        curr_predictions_test, stats_test = trainer.inference(\n",
    "            data,\n",
    "            walk_length=3,\n",
    "            sizes=(5, 2, 1),\n",
    "            batch_size=256,\n",
    "            shuffle=False,\n",
    "            log_stats=False\n",
    "        )\n",
    "        predictions_test.append(curr_predictions_test)\n",
    "        ys_test.append(data.y)\n",
    "    predictions_test = torch.vstack(predictions_test)\n",
    "    ys_test = torch.hstack(ys_test)\n",
    "\n",
    "    unintended_dataset_val = TensorSupervisedDataset(\n",
    "        x=predictions_test,\n",
    "        y=ys_test\n",
    "    )\n",
    "    unintended_dataloader_val = DataLoader(unintended_dataset_val, batch_size=256, shuffle=False)\n",
    "    preds_val, metrics_val = unintended_model.predict(unintended_dataloader_val)\n",
    "    trainer.log_metrics(\n",
    "        epoch=epoch,\n",
    "        metrics={\n",
    "            \"Unintended: train loss\": metrics[\"mean_train_loss\"],\n",
    "            \"Unintended: val loss\": metrics_val[\"mean_loss\"],\n",
    "            \"Unintended: MSE train\": metrics[\"MeanSquaredError\"],\n",
    "            \"Unintended: MSE val\": metrics_val[\"MeanSquaredError\"],\n",
    "            \"Unintended: MAE train\": metrics[\"MeanAbsoluteError\"],\n",
    "            \"Unintended: MAE val\": metrics_val[\"MeanAbsoluteError\"],\n",
    "            **statistics\n",
    "        }\n",
    "    )"
   ],
   "metadata": {
    "id": "3crRNg6HQFF6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}